<!doctype html>
<html lang="en">
    <head>
        <meta charset="UTF-8">
        <title>Yagya R Panddeya - Resume</title>
        <link rel="stylesheet" href="style.css">
        <link href="https://fonts.googleapis.com/css?family=Merriweather:300,400,700|Source+Sans+Pro:400,400i" rel="stylesheet">
    <body>
        <div class="page">
		<div class="section row">
                <h1 class="col"><span style="font-weight:700">Yagya</span> Raj Pandeya, Ph.D.</h1>
                <div class="contact-info col-right">
			<div><img src="YagyaPandeya.JPG" alt=""></div>
			<div>Citizenship: Nepal</div>
                    	<div>Permanent Address: Jhalari-7, Kanchanpur, Nepal</div>
			<div>Mailing Address: Jeonbuk National University, Jeonju city, South Korea</div>
			<div>Date of birth: 25th July, 1988</div>
			<div>Phone: (+82)01044049848</div>
                    <div><a href="mailto:yagyapandeya@gmail.com">yagyapandeya@gmail.com</a></div>
                </div>
            </div>
	
	<div class="section row">
                <h2 class="col">CAREER OBJECTIVE</h2>
                <div class="section-text col-right">
                    <h3><span class="emph">An enthusiastic and adaptive person with a broad and acute interest 
			in the discovery of new innovative information technologies. 
			I particularly enjoy collaborating with tech exports from different 
			disciplines of computer science to develop new skills and solve new challenges.</h3>  
            </div></div>

            <div class="section row">
                <h2 class="col">Education</h2>
                <div class="section-text col-right">
		<div><a href="https://www.jbnu.ac.kr/kor/"><h3><span class="emph">Jeonbuk National University</h3></a></div>
                    <div>Major in Machine Learning and Deep Neural Networks</div>
                    <div class="row">
                        <div class="col light">CGPA: 4.43/4.50</div>
                        <div class="col-right light">Sep. 2017 - Ongoing</div>
                    </div>
		<div><a href="https://pu.edu.np/"><h3><span class="emph">Pokhara University</h3></a></div>
                    <div><a href="https://ncit.edu.np/">Nepal College of Information Technology, Balkumari, Lalitpur(PU Affiliated College)</a></div>
                    <div class="row">
                        <div class="col light">Rank: Dean's List (CGPA: 3.97/4)</div>
                        <div class="col-right light	">2014 </div>
                    </div>
		
		<div><a href="https://pu.edu.np/"><h3><span class="emph">Pokhara University(PU)</h3></a></div>
                    <div><a href="http://nast.edu.np/">National Academy of Science and Technology, Dhangadhi, Kailali(PU Affiliated College)</a></div>
                    <div class="row">
                        <div class="col light">Rank: CGPA: 3.54/4</div>
                        <div class="col-right light">2010 </div>
                    </div>
		<div><a href="http://www.neb.gov.np/"><h3><span class="emph">National Examination Board(NEB)</h3></a></div>
                    <div><a href="http://radianths.edu.np/">Radiant Secondary School, Mahendranagar, Kanchanpur(Under NEB)(Class XII)</a></div>
                    <div class="row">
                        <div class="col light">OVERALL PERCENTAGE: 55%</div>
                        <div class="col-right light">2006 </div>
                    </div>
		<div><a href="http://www.neb.gov.np/"><h3><span class="emph">National Examination Board(NEB)</h3></a></div>
                    <div>Shree Radha-Krishna Secondary School, Tiltali, Doti(Under Government of Nepal)(Class X)</div>
                    <div class="row">
                        <div class="col light">OVERALL PERCENTAGE: 74%</div>
                        <div class="col-right light">2003 </div>
                    </div>
                </div>
            </div>



	<div class="section row">
                <h2 class="col">Work Experience</h2>
                <div class="section-text col-right">
		<div><a href="http://ailab.jbnu.ac.kr/"><h3><span class="emph">Fuzzy Logic and Artificial Intelligence Laboratory at Jeonbuk National University</h3></a></div>
                    <div>Machine learning and Deep learning based research</div>
		<div>Address: Jeonju City, South Korea</div>
                    <div class="row">
                        <div class="col light">Status: Ph.D. Fellow</div>
                        <div class="col-right light">27 April 2017 - Ongoing</div>
                    </div>

		<div><a href="http://www.moha.gov.np/">Ministry of Home Affairs (Government of Nepal)</h3></a></div>
                    <div>National Security Control</div>
			<div>Address: Singhdurbar, Kathmandu, Nepal</div>
                    <div class="row">
                        <div class="col light">Status: IT officer</div>
                        <div class="col-right light">27 April 2015 - Aug 22 2016</div>
                    </div>
		
		<div><a href="http://nast.edu.np/"><h3><span class="emph">Head of Computer Engineering Department</h3></a></div>
                    <div>Assistant Professor and Department head. </div>
			<div>Address: Dhangadhi, Kailali, Nepal</div>
                    <div class="row">
                        <div class="col light">Status: Head of Department</div>
                        <div class="col-right light">12 Feb 2013 - 27 April 2015</div>
                    </div>

		<div><a href="https://www.wvi.org/nepal"><h3><span class="emph">World Vision International Nepal</h3></a></div>
                    <div>Database management. </div>
			<div>Address: Dhangadhi, Kailali, Nepal</div>
                    <div class="row">
                        <div class="col light">Status: IT officer (Internship)</div>
                        <div class="col-right light">21 Aug. 2010 - 10 Sep. 2010</div>
                    </div>

		<div><a href="https://www.rvwrmp.org.np/"><h3><span class="emph">Rural Village Water Resources Management Project (RVWRMP)</h3></a></div>
                    	<div>Database management.</div>
			<div>Address: Dhangadhi, Kailali, Nepal</div>
                    <div class="row">
                        <div class="col light">Status: IT officer (Internship)</div>
                        <div class="col-right light">4 Dec. 2009 - 12 Feb. 2010</div>
                    </div>
		
                </div>
            </div>


            <div class="section row">
                <h2 class="col">Projects</h2>

    

		<div class="section-text col-right">
		<div class="row">
                        <div class="col">
                            <h3>Sound Event Labeling Tool</h3>
                        </div>
                    </div>
                    <div class="row subsection">
                        <div class="emph col">Jeonbuk National University | Advisors: <a href="http://ailab.jbnu.ac.kr/intro_prof.php">Joonhwan Lee</a></div>
                        <div class="col-right light">Dec. 2019 - Sep. 2020</div>
                    </div>
                    <ul class="desc">
			<li>Article title:<b> A Cow Sound Labeling Tool for Audio-Video Data.</b><b><span style="color:#FF5733;">[SCIE Journal]</span></b></li>
                        <li><b>Semi-supervised Sound Event Annotation Tool </b> using <b>audio and video</b> as input.</li>
                        <li>Automatic event detector is used to detect the audio event.</li>
                        <li>Based on the automatic detector result, an human annotation have to refine the annotation boundary.</li>
			<li>Easy to use, better audio visualization, python based and output in easy CSV data file.</li>
                        <li>Diversified annotation tool for any rare sound event.</li>
			<li>Under review.</li>
               
                    </div>
		
		<div class="section-text col-right">
                    <div class="row">
                        <div class="col">
                            <h3>Music Source Seperation</h3>
                        </div>
                    </div>
                    <div class="row subsection">
                        <div class="emph col">Jeonbuk National University | Advisors: <a href="http://ailab.jbnu.ac.kr/intro_prof.php">Joonhwan Lee</a></div>
                        <div class="col-right light">June 2020 - Nov. 2020</div>
                    </div>
                    <ul class="desc">
			<li>Article title:<b><a href="https://ieeexplore.ieee.org/document/9257356">Parallel Stacked Hourglass Network for Music Source Separation.</a></b><b><span style="color:#FF5733;">[SCIE Journal]</span></b></li>
                        <li><b>Prepared Korean traditional song (Pansori) dataset with 3 sources.</li>
			<li>Korean traditional music Pansori dataset, MIR-1K dataset, and DSD100 dataset used in experiment. </li>
                        <li>Proposed a novel parallel stacked hourglass network (PSHN) with multiple band spectrograms.</li>
                        <li>Ablation study on proposed and past architecture.</li>
                        <li>State-of-art result.</li>
			<li>Puplished on <b><a href="https://ieeeaccess.ieee.org/"> IEEE Access </a></b>in Nov. 2020</li>
               
                    </div>

		
		<div class="section-text col-right">
		<div class="row">
                        <div class="col">
                            <h3>CNN Based Sound Event Detection in Cowshed</h3>
                        </div>
                    </div>
                    <div class="row subsection">
                        <div class="emph col">Jeonbuk National University | Advisors: <a href="http://ailab.jbnu.ac.kr/intro_prof.php">Joonhwan Lee</a></div>
                        <div class="col-right light">Dec. 2019 - Sep. 2020</div>
                    </div>
                    <ul class="desc">
                        <li>Article title:<b><a href="http://sigongji.ictc.org/wp/SessionPaperList.asp?code=Session%20III-1">Sound Event Detection in Cowshed using Synthetic data and Convolutional Neural Network</a></b><b><span style="color:#FF5733;">[IEEE Conference]</span></b></li>
                        <li>CNN based sound event detection.</li>
			<li>Sound event annotaion tool.</li>
                        <li>Sound localization and classification.</li>
			<li>Puplished on <b><a href="http://ictc.org/"> ICTC2020 </a></b>in Sep. 2020</li>
               
                    </div>

		
		<div class="section-text col-right">
		<div class="row">
                        <div class="col">
                            <h3>Cow Sound Event Localization and Classification</h3>
                        </div>
                    </div>
                    <div class="row subsection">
                        <div class="emph col">Jeonbuk National University | Advisors: <a href="http://ailab.jbnu.ac.kr/intro_prof.php">Joonhwan Lee</a></div>
                        <div class="col-right light">Dec. 2019 - Sep. 2020</div>
                    </div>
                    <ul class="desc">
                        <li>Article title:<b><a href="https://ieeexplore.ieee.org/document/9187249/">Visual Object Detector for Cow Sound Event Detection</a></b><b><span style="color:#FF5733;">[SCIE Journal]</span></b></li>
                        <li>Cow sound event detection dataset with 4 class categories.</li>
			<li>CNN used for sound event detection using Cow sound dataset and <a href="https://urbansounddataset.weebly.com/urbansound8k.html">UrbanSound8K dataset.</a></li>
                        <li>Visual object detection architecture (F-RCNN, CF-RCNN, FPN, C-FPC) used for audio event detection (in Log Mel-Spectrogram).</li>
			<li>Compare the proposed CNN and Visual object detection architecture using three test dataset.</li>
			<li>Puplished on <b><a href="https://ieeeaccess.ieee.org/"> IEEE Access </a></b>in Sep. 2020</li>
               
                    </div>
		
		<div class="section-text col-right">
		<div class="row">
                        <div class="col">
                            <h3>Music-Video Emotion Classification</h3>
                        </div>
                    </div>
                    <div class="row subsection">
                        <div class="emph col">Jeonbuk National University | Advisors: <a href="http://ailab.jbnu.ac.kr/intro_prof.php">Joonhwan Lee</a></div>
                        <div class="col-right light">Jan. 2019 - Sep. 2019</div>
                    </div>
                    <ul class="desc">
                        <li>Article title:<b><a href="https://link.springer.com/article/10.1007/s11042-020-08836-3">Deep Learning-Based Late Fusion of Multimodal Information for Emotion Classification of Music Video</a></b><b><span style="color:#FF5733;">[SCIE Journal]</span></b></li>
                        <li>Music-Video emotion classification using audio and video multimodal network architecture.</li>
                        <li>Use pretrained CNN for audio and 3D video model (I3D and C3D).</li>
			<li>The network learned features ate late fused and compare the impact of network feature fusion.</li>
                        <li>Cross validation and network feature fusion.</li>
			<li>Puplished on <b><a href="https://www.springer.com/journal/11042"> Multimedia Tools and Applications </a></b>in Sep. 2020</li>
               
                    </div>
		
		
		<div class="section-text col-right">
		<div class="row">
                        <div class="col">
                            <h3>Music Video Emotion Analysis</h3>
                        </div>
                    </div>
                    <div class="row subsection">
                        <div class="emph col">Jeonbuk National University | Advisors: <a href="http://ailab.jbnu.ac.kr/intro_prof.php">Joonhwan Lee</a></div>
                        <div class="col-right light">Dec. 2018 - March 2019</div>
                    </div>
                    <ul class="desc">
                        <li>Article title:<b><a href="https://www.semanticscholar.org/paper/Music-Video-Emotion-Analysis-Using-Late-Fusion-of-Pandeya-Lee/594b7ec2607cf220a8d3ff64340dd5607b56ecb2">Music-Video Emotion Analysis Using Late Fusion of Multimodal</a></b><b><span style="color:#FF5733;">[Conference]</span></b></li>
                        <li>Music video emotion dataset of six class category.</li>
                        <li>Audio-video multimodal architecture.</li>
			<li>C3D pretrained network and CNN pretrained audio network feature fusion.</li>
                        <li>Emotion representation in 2D emotion space.</li>
			<li>Puplished on <b><a href="http://www.allconfs.org/meeting/index_en.asp?id=5848"> ITEEE 2019 Conference </a></b>in 2019</li>
               
                    </div>
		

		<div class="section-text col-right">
		<div class="row">
                        <div class="col">
                            <h3>Domestic Cat Sound Classification</h3>
                        </div>
                    </div>
                    <div class="row subsection">
                        <div class="emph col">Jeonbuk National University | Advisors: <a href="http://ailab.jbnu.ac.kr/intro_prof.php">Joonhwan Lee</a></div>
                        <div class="col-right light">Dec. 2017 - Sep. 2018</div>
                    </div>
                    <ul class="desc">
                        <li>Article title:<b><a href="https://www.mdpi.com/2076-3417/8/10/1949">Domestic Cat Sound Classification Using Learned Features from Deep Neural Nets</a></b><b><span style="color:#FF5733;">[SCI Journal]</span></b></li>
                        <li>CNN and CDBN network architecture.</li>
                        <li>Cat sound dataset preparation of 10 class categories.</li>
			<li>Frequency division average pooling (FDAP) technique instead of global average pooling (GAP) to make a robust prediction using various frequency band features.</li>
                        <li>Audio augmentation and learned feature visualization.</li>
			<li>Puplished on <b><a href="https://www.mdpi.com/journal/applsci"> Applied Science </a></b>in Sep 2018</li>
               
                    </div>
		
		<div class="section-text col-right">
		<div class="row">
                        <div class="col">
                            <h3>Domestic Cat Sound Classification using Transfer Learning</h3>
                        </div>
                    </div>
                    <div class="row subsection">
                        <div class="emph col">Jeonbuk National University | Advisors: <a href="http://ailab.jbnu.ac.kr/intro_prof.php">Joonhwan Lee</a></div>
                        <div class="col-right light">Dec. 2017 - March 2018</div>
                    </div>
                    <ul class="desc">
                        <li>Article title:<b><a href="http://doi.org/10.5391/IJFIS.2018.18.2.154">Domestic Cat Sound Classification Using Transfer Learning</a></b><b><span style="color:#FF5733;">[SCIE Journal]</span></b></li>
                        <li>Cat sound dataset with 10 class categories.</li>
                        <li>Use pretrained CNN for feature extraction and make feature classification.</li>
			<li>Machine learning classifier and deep learning classifier comparision.</li>
                        <li>Ensemble and data augmentation.</li>
			<li>Puplished on <b><a href="http://www.ijfis.org/about/sub01.html"> International Journal of Fuzzy Logic and Intelligent Systems </a></b>in June 2018</li>
               
                    </div>
		

            </div>
            <div class="section row">
                <h2 class="col">Achievements</h2>
                <div class="section-text col-right">

                    <div class="row subsection">
                        <li>Winner <a href="http://www.studyinkorea.go.kr/"><b>Korean Government Scholarship Program (KGSP) (2016)</b></a></li>
                        <li>Awarded by <b>Dean's List</b> of <a href="https://pu.edu.np/">Pokhara University</a> in 2014</li>
                            
                    </div>
                    
                </div>

            </div>
            <div class="section row">
                <h2 class="col">Language Skill</h2>
                <div class="section-text col-right row">
                    <ul class="skills" style="width:35%">
                        <li>English Language</li>
                        <li>Korean Language</li>
                        <li>Hindi</li>
			<li>Nepali</li>
                    
                    </ul>

                    <ul class="skills" style="width:35%">
                        <li>Good</li>
                        <li>Moderate (1 year course)(<a href="https://www.topik.go.kr/usr/lang/index.do?home_seq=221">TOPIK</a>-3)</li>
                        <li>Very good</li>
			<li>Very good</li>
                        
                    </ul>
                    
                </div>
            </div>
            <div class="section row">
                <h2 class="col">Technical Skills</h2>
                <div class="section-text col-right row">
                    <ul class="skills" style="width:35%">
                        <li>Programming Languages</li>
                        <li>Deep learning Framework</li>
                        <li>Platforms</li>
                        <li>Networking</li>
			<li>I.D.E Skills</li>
                    </ul>
                    <ul class="skills" style="width:35%">
                        <li>Python, C, C++, PHP</li>
                        <li>TensorFlow, Keras, PyTorch</li>
                        <li>Linux, Windows, CUDA</li>
                        <li>CCNA</li>
			<li>Dreamweaver, Eclipse, UML, PyCharm </li>
                        
                    </ul>
                    
                </div>
            </div>
            
	
	<div class="section row">
                <h2 class="col">References</h2>
                <div class="section-text col-right">
		<div><a href="http://ailab.jbnu.ac.kr/intro_prof.php"><h3><span class="emph">Prof. Joonwhoan Lee</h3></a></div>
                    <div>Ph.D. Adviser</div>
			<div>Institude: <a href="https://www.jbnu.ac.kr/kor/">Jeonbuk National University</a></div>
			<div>Ph No.: +82-63-270-2406, +82-010-9855-2406</div>
			<div>Email: <a href="mailto:chlee@chonbuk.ac.kr">chlee@chonbuk.ac.kr</a></div>
		
		<div><a href="https://scholar.google.com/citations?user=S1dL69sAAAAJ&hl=en"><h3><span class="emph">Prof. Shashidhar Ram Joshi</h3></a></div>
                    <div>Master Adviser</div>
			<div>Institude: <a href="https://pu.edu.np/">Pokhara University</a></div>
			<div>Ph No.: +977-01-5534070 </div>
			<div>Email varify at: https://ioe.edu.np/</div>
		
		<div><h3><span class="emph">Mr. SS Mudvari</h3></div>
                    <div>NAST Engineering College Principal</div>
			<div>Institude: <a href="http://nast.edu.np/">National Academy of Science & Technology</a></div>
			<div>Ph No.: +977-91-523312,521312 </div>
			<div>Email varify at: nastdhn@gmail.com, nastdhn@yahoo.com</div>
                </div>
            </div>


            <div class="section row">
                <h2 class="col">Current Research</h2>
                <div class="section-text col-right">
                    <div><a>Music-Video emotion analysis.</a></div>
                    <div><a>Multiple action recognition in cowshed.</a></div>
                    <div><a>Plant disease detection.</a></div>
                    <div><a>Cattle emotion and behavior analysis.</a></div>
                    <div><a>Music source seperation.</a></div>

                </div>
            </div>
        </div>
    </body>
    
            </html>
